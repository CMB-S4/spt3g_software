----------------
Data Acquisition
----------------

This software provides, in addition to data processing, facilities for data acquisition. The goal is to have a unified framework for simulations, data acquisition, and analysis.

.. contents:: Contents

DfMux
=====

Bolometer Data
~~~~~~~~~~~~~~

The ``dfmux`` project provides two classes that can be used for event-driven acquisition of bolometer timestreams from IceBoards. The core class, ``dfmux.DfMuxCollector``, listens for multicast packets on an interface given by its first argument. Its second argument is a ``dfmux.DfMuxBuilder`` object to which the collected data is reported. The ``dfmux.DfMuxBuilder`` is a subclass of ``G3EventBuilder`` (see G3EventBuilder_ below) that assembles mux packets into frames, with one sample from each readout channel per frame. To do this, it is passed the number of boards to expect for a complete sample.

.. code-block:: python

	pipe = core.G3Pipeline()
	builder = dfmux.DfMuxBuilder(len(hwm.query(pydfmux.core.dfmux.IceBoard).all()))
	collector = dfmux.DfMuxCollector("192.168.1.4", builder)
	collector.Start()
	pipe.Add(builder)

The above example listens for the number of boards included in the specified pydfmux hardware map on the host computer's interface with IP address 192.168.1.4 and then emits frames into the processing queue. Note that this listens to all boards reachable via the specified network interface and that the IP address is *not* a board IP.

As an alternative, you can specify a specific list of boards to listen for. This is useful when using a hardware map containing only a subset of the boards on the network, which would otherwise trigger dropped packet errors. An equivalent example to the above code follows:

.. code-block:: python

	pipe = core.G3Pipeline()
	builder = dfmux.DfMuxBuilder([int(board.serial) for board in hwm.query(pydfmux.IceBoard)])
	collector = dfmux.DfMuxCollector("192.168.1.4", builder)
	collector.Start()
	pipe.Add(builder)

.. note::

	The mux system can deliver large numbers of UDP packets rapidly. If you see warnings about missed samples, you may need to increase the maximum size of the kernel UDP receive queue. On Linux, this can be accomplished by changing the value in ``/proc/sys/net/core/rmem_max``. On FreeBSD and Mac OS X, the maximum is in the sysctl ``kern.ipc.maxsockbuf``. A value of 5000000000 seems to work well.

.. note::

	On some versions of Linux with 128x DfMux firmware, you will need to disable strict reverse-path validation in the kernel to take data. This can be accomplished by setting the sysctl ``net.ipv4.conf.all.rp_filter`` to 0.

This code can also be used to collect data from legacy boards with DAN firmware if you are so inclined by using the ``dfmux.LegacyDfMuxCollector`` class in place of ``dfmux.DfMuxCollector``.

Data Structures
_______________

Frames generated by DfMuxBuilder contain two keys: "EventHeader" and "DfMux".

"EventHeader" is a ``G3Time`` object containing the IRIG time of the first sample in the frame. If all the boards are synchronized correctly, this will also be the timestamp attached to all DfMux board samples.

"DfMux" is an object of type ``DfMuxMetaSample``. This is a dictionary that maps board serial number to a ``DfMuxBoardSamples`` object. This in turn is a dictionary that maps readout module number (0-7) to a ``DfMuxSample`` object. This contains the IRIG timestamp for the data in its ``Timestamp`` member as well as a 128-element array of all the bolometer data in ``Samples``, stored with I and Q interleaved (so element 0 is channel 1/I, 1 is channel 1/Q, 2 is channel 2/I, etc.).

As an example:

.. code-block:: python

	channel2q = frame['DfMux'][frame['DfMux'].keys()[0]][0][3]

This retrieves data from the first board in the array, module 1, channel 2, modulation Q.

Housekeeping Data
~~~~~~~~~~~~~~~~~

DfMux board housekeeping is collected by the ``dfmux.HousekeepingConsumer`` class. It will query all of the boards in the most recent wiring map (see `The Wiring Map`) when a Housekeeping frame appears in the datastream, placing the results in the key ``DfMuxHousekeeping``. 

Housekeeping frames at fixed intervals can be generated using ``dfmux.PeriodicHousekeepingCollector``. Note that collecting housekeeping information generates noise in detector timestreams and should be done only at times that you do not care about the data.

.. note:: 

	Housekeeping collecting can take up to a few seconds. If you are worried about pipeline stalls, you may want to run the housekeeping consumer in a subprocess (see ``G3Pipeline.Add()``).

The resulting data are stored in a ``dfmux.DfMuxHousekeepingMap`` map, indexed by board serial number. This can be cross-correlated to the wiring map data. Mezzanines, modules, and channels stored in the elements are 1-indexed, matching the convention from pydfmux.

For ease of cross-correlation, there is a function ``dfmux.HousekeepingForBolo`` that can will look up the housekeeping information for a particular named bolometer.

.. code-block:: python

	hk = dfmux.HousekeepingForBolo(self.hkmap, self.wiringmap, 'Bolometer')

By default, this only returns information for the channel (notably containing the carrier amplitude and frequency). If you want the board, mezzanine, module, and channel information returned as a tuple, in that order, pass the keyword argument ``all_hk=True``.

Building Timestreams
====================

All analysis tools use data in the form of G3Timestreams, indexed by bolometer ID. Timestreams are typically stored in a Scan (see :doc:`frames`) frame, which is constructed from a wiring map and Timepoint frames using DfMuxCollator_.

The Wiring Map
~~~~~~~~~~~~~~

The wiring map, stored in a Wiring frame at the beginning of data taking, stores the mapping between bolometer ID and (Board Slot/Address, SQUID, Readout channel) tuples -- the information required to connect a ``DfMuxMetaSample`` object to bolometer samples. The wiring map is stored as the key ``WiringMap`` in an object of type ``DfMuxWiringMap`` in a Wiring frame. In almost all cases, this is inserted into the data stream by the ``PyDfMuxHardwareMapInjector`` module. This module is typically inserted as the first module following the ``DfMuxBuilder`` and takes a pydfmux hardware map as input (note: *not* a pydfmux session):

.. code-block:: python

	pipe.Add(dfmux.PyDfMuxHardwareMapInjector, pydfmux_hwm=hwm)

DfMuxCollator
~~~~~~~~~~~~~

The ``DfMuxCollator`` class builds Scan frames (and timestreams) from Timepoint frames using the wiring map. Scan boundaries are signalled by the insertion of empty Scan frames into the data stream. When the ``DfMuxCollator`` object encounters a Scan frame, it will do the following:

	1) Accumulate all subsequent DfMux samples into two timestream maps, indexed by the bolometer IDs stored in the wiring map: ``RawTimestreams_I`` and ``RawTimestreams_Q``. Any samples for detectors not listed in the wiring map will be discarded. Accumulation ends with the next scan frame or the end of data processing, whichever comes first.
	2) Accumulate all scalar floating point numbers in the timepoint frames into timestreams with the same names. This is useful to store non-bolometer data such as telescope pointing.
	3) By default, FLAC compression is enabled for all bolometer timestreams and the source timepoint frames are discarded. These can be changed using the two arguments to the constructor of ``DfMuxCollator``.

Empty scan frames can be inserted using a short Python module at appropriate boundaries. A trivial example is the ``dfmux.FixedLengthScans`` module, which makes "scans" of some integer number of mux samples (by default, 1000 frames). In practice, you would want to break scans by GCP commands or analysis of telescope pointing.

.. code-block:: python

	pipe.Add(dfmux.PyDfMuxHardwareMapInjector, pydfmux_hwm=hwm)
	pipe.Add(dfmux.FixedLengthScans, N=1000)
	pipe.Add(dfmux.DfMuxCollator)

Collecting data to a NetCDF file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The ``dfmux.NetCDFDump`` module takes timepoint frames and writes them to a NetCDF 3 file that can be opened using a variety of software packages, most notably KST, which will also monitor the file for updates. All sample points present in the wiring map are written to the output file with both I and Q demodulations, denoted by an ``_I`` or ``_Q`` suffix appended to the bolometer ID in the wiring map. In addition, a field called ``Time`` will be added containing the time of the sample (from the ``EventHeader`` key) in seconds since the UNIX epoch (Jan. 1, 1970). This time can be decoded using the python ``time`` module.

An example follows, including the addition of the wiring map from pydfmux and construction of the event builder:

.. code-block:: python

	pipe = core.G3Pipeline()
	builder = dfmux.DfMuxBuilder(len(hwm.query(pydfmux.core.dfmux.IceBoard).all()))
	collector = dfmux.DfMuxCollector("192.168.1.4", builder)
	pipe.Add(builder)

	# Insert current hardware map into data stream. This is critical to get the
	# channel -> board/module mapping needed to do anything useful with the data
	pipe.Add(dfmux.PyDfMuxHardwareMapInjector, pydfmux_hwm=hwm)

	pipe.Add(dfmux.NetCDFDump, filename=sys.argv[1])

This is contained in runnable form in ``dfmux/bin/ledgerman.py``.

Note that the version of KST installed from the default package repository under Ubuntu may not have support for reading NetCDF files produced by ledgerman. The version available from the KST PPA repository is compiled with NetCDF support (http://launchpad.net/~kst-plot/+archive/ubuntu/ppa).

Core Tools
==========

G3EventBuilder
~~~~~~~~~~~~~~

Implements an asynchronous frame builder based on frame objects delivered to its non-blocking ``AsyncDatum()`` call. When these arrive, the object calls the pure virtual method ``ProcessNewData()`` from a main thread. This method is responsible for assembling the data and eventually passing a complete frame to ``FrameOut()``, which will begin processing it in the pipeline. This is a C++-only abstract base class and is useful only when building a new data acquisition system.

G3TriggeredBuilder
~~~~~~~~~~~~~~~~~~

This is the analog of G3EventBuilder for non-self-triggering systems (i.e. systems that poll for new data rather than streaming it). This can be used for once-every-N DAQ tasks like collecting housekeeping data.

ledgerman
=========

An example tool called ``ledgerman`` is included that collects data from the mux boards and writes it to a NetCDF file that can be read with kst. It is installed under ``bin`` in your build directory and will be available in your PATH if you have run ``env-shell.sh``.

.. code-block:: sh

	$ ledgerman /path/to/a/pydfmux/hardware/map.yaml output.nc

To see the frames as they go by:

.. code-block:: sh

	$ ledgerman -v /path/to/a/pydfmux/hardware/map.yaml output.nc

Like the other modules, you may see a few warnings about missing data immediately after it starts in the event that it starts collecting data midway through a sample. There should not be any warning messages after that.

